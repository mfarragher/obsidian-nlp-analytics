{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03b26a80",
   "metadata": {},
   "source": [
    "**_Prototype_ - auto-suggested wikilinks via topic modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7618334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')  # go to project dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b7cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import obsidiantools.api as otools\n",
    "\n",
    "import src\n",
    "from src.vault import get_vault\n",
    "from src.nlp import VaultNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe2cdad",
   "metadata": {},
   "source": [
    "# Original vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e321bf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.88 s, sys: 22.7 ms, total: 4.9 s\n",
      "Wall time: 4.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "VAULT = get_vault('FILM_NOIR_VAULT_DIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f107ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = VAULT.get_note_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80050e85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d77b66",
   "metadata": {},
   "source": [
    "The dataset used to produce the vault takes IDs from these lists:\n",
    "- [Film noir](https://www.imdb.com/search/title/?genres=film_noir&title_type=feature&sort=user_rating%2Cdesc)\n",
    "- [Neo-noir](https://www.imdb.com/list/ls026035968/?sort=user_rating%2Cdesc&st_dt=&mode=detail&page=1&title_type=movie&num_votes=10000%2C&release_date=1960%2C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8b871f",
   "metadata": {},
   "source": [
    "# Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70c461f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notes: 122\n"
     ]
    }
   ],
   "source": [
    "print(f\"Notes: {df[df['note_exists']].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61411ed9",
   "metadata": {},
   "source": [
    "Semi-supervised modelling by specifying **anchor words** for each topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ef0894",
   "metadata": {},
   "source": [
    "**I use the anchor words to formulate wikilinks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c2f8166",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_WORDS = [['murder', 'violence', 'death', 'die', 'dead', 'killed', 'gun'],\n",
    "                ['love', 'loves', 'lover', 'obsession', 'obsess',\n",
    "                 'romance', 'desire', 'relationship', 'sex'],\n",
    "                ['torment', 'fear', 'domineering', 'demons', 'controlling'],\n",
    "                ['revenge', 'avenge', 'vengeance', 'betray', 'jealous'],\n",
    "                ['corruption', 'corrupt', 'injustice', 'lies', 'lied'],\n",
    "                ['crime', 'criminal']\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a41c89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = VaultNLP(VAULT)\n",
    "nlp.anchor_words = ANCHOR_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6d3ba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 102 ms, sys: 954 µs, total: 102 ms\n",
      "Wall time: 102 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nlp.generate_sparse_word_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a3c3f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Anchor word not in word column labels provided to CorEx: obsess\n",
      "CPU times: user 21.7 s, sys: 332 ms, total: 22 s\n",
      "Wall time: 22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nlp.fit_anchored_topic_model(n_hidden=len(ANCHOR_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3034897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: gun, dead, killed, death, murder, gets, shows, running, watching, day\n",
      "1: love, relationship, lover, sex, naked, romance, house, sexual, suspicions, scene\n",
      "2: walks, coffee, showed, domineering, sort, believe, thinks, collapses, talk, elderly\n",
      "3: vengeance, betray, men, notices, opens, morning, notice, inside, train, come\n",
      "4: corrupt, lies, corruption, seen, lights, telling, make, enters, says, coming\n",
      "5: crime, criminal, arrives, investigation, called, fact, picked, cars, having, garage\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(nlp.anchor_words)):\n",
    "    topic_words, _, _ = zip(*nlp.anchor_topic_model.get_topics(topic=n))\n",
    "    print('{}: '.format(n) + ', '.join(topic_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e76a11",
   "metadata": {},
   "source": [
    "# Auto-suggest links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "822749e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb9f44b",
   "metadata": {},
   "source": [
    "## clean note index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f66ed90",
   "metadata": {},
   "source": [
    "For this step, I clean up IMDB synoposes that don't have spaces as expected to separate sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40a558a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up text: add space after full stops\n",
    "clean_text_index = {k: re.sub(r'\\.(?! )', '. ', re.sub(r' +', ' ', v))\n",
    "                    for k,v in VAULT.readable_text_index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23735fc",
   "metadata": {},
   "source": [
    "## lemmatise anchor words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "637859d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "978d06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchor_tokens(anchor_keywords_list):\n",
    "    anchor_kwords = nlp(' '.join(list(itertools.chain(*ANCHOR_WORDS))))\n",
    "    \n",
    "    anchor_tokens = [w.lemma_ for w in anchor_kwords\n",
    "                     if not w.is_stop and\n",
    "                     not w.is_punct and not w.like_num]\n",
    "\n",
    "    # unique list\n",
    "    anchor_tokens = list(set(anchor_tokens))\n",
    "    return anchor_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78781a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_tokens = get_anchor_tokens(ANCHOR_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b1241e",
   "metadata": {},
   "source": [
    "# Replace text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ca5fe",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a240ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_of_words_with_lemmas(clean_text_index):\n",
    "    clean_text_and_lemmas_index = {k: [(w, w.lemma_) for w in nlp(v)]\n",
    "                                   for k,v in clean_text_index.items()}\n",
    "    return clean_text_and_lemmas_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c6b63b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_of_keyword_matches(clean_text_and_lemmas_index):\n",
    "    clean_text_and_lemmas_index = get_index_of_words_with_lemmas(clean_text_index)\n",
    "    \n",
    "    # each note (k) has a list of (word, lemma) matches:\n",
    "    clean_text_lemmas_match = {k: list(filter(lambda x: (x[1] in anchor_tokens), v))\n",
    "                               for k,v in clean_text_and_lemmas_index.items()}\n",
    "    return clean_text_lemmas_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45da9c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_with_lemmas_index = get_index_of_words_with_lemmas(clean_text_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49ad4e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_lemmas_match = get_index_of_keyword_matches(words_with_lemmas_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7b7f1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(kill, 'kill'),\n",
       " (killed, 'kill'),\n",
       " (killed, 'kill'),\n",
       " (kills, 'kill'),\n",
       " (betrayed, 'betray')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text_lemmas_match.get('The Killing (1956)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "274926a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_word_to_lemma_replacement_map(clean_text_lemmas_match):\n",
    "    # dict of <lemma>:<alias>\n",
    "    # reversed list of tuples so that the 'first key wins', rather than last\n",
    "    clean_text_match_first_word = dict()\n",
    "    for note_name in clean_text_lemmas_match.keys():\n",
    "        # new dict:\n",
    "        clean_text_match_first_word[note_name] = {\n",
    "            v:k for k,v in reversed(clean_text_lemmas_match[note_name])}\n",
    "    # re-order dict to <alias>:<lemma> for easier replacement:\n",
    "    word_replace_map = dict()\n",
    "    for k, v_dict in clean_text_match_first_word.items():\n",
    "        word_replace_map[k] = {v:k for k,v in v_dict.items()}\n",
    "    return word_replace_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "591cdea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_to_wikilink_replacement_map(clean_text_lemmas_match):\n",
    "    mp = _get_word_to_lemma_replacement_map(clean_text_lemmas_match)\n",
    "    \n",
    "    # swap k,v - the words as k, the wikilinks as v:\n",
    "    for main_k, inner_dict in mp.items():\n",
    "        mp[main_k] = {v:''.join([\"[[\",v,\"]]\"]) if str(k)==v\n",
    "                      else ''.join([\"[[\",v,\"|\",str(k),\"]]\"])\n",
    "                      for k,v in inner_dict.items()}\n",
    "    return mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d79da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_replace_map = get_word_to_wikilink_replacement_map(\n",
    "    clean_text_lemmas_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f39d1fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'betray': '[[betray|betrayed]]', 'kill': '[[kill]]'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_replace_map.get('The Killing (1956)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216773ac",
   "metadata": {},
   "source": [
    "## word replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c259b",
   "metadata": {},
   "source": [
    "Loop over each file to replace the first instance of a topic word with a wikilink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6045d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_source_text = clean_text_index.copy()\n",
    "# (rather than VAULT.source_text_index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a1315ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmas_to_words(note_name):\n",
    "    l = words_with_lemmas_index.get(note_name)\n",
    "    w_to_lemmas = {k:v for k,v in dict(reversed(l)).items()}\n",
    "    lemma_to_ws = {v:k for k,v in w_to_lemmas.items()}\n",
    "    return lemma_to_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72bdae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69d9cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `new_source_text` to store text for final export:\n",
    "new_source_text = clean_text_index.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fb591f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one Matcher obj:\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8521ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for note_name, lemma_to_link_map in word_replace_map.items():    \n",
    "    orig_doc = nlp(new_source_text[note_name])\n",
    "    new_doc = orig_doc.copy()\n",
    "    \n",
    "    lemmas_to_words = get_lemmas_to_words(note_name)\n",
    "    for lemma, new_link in lemma_to_link_map.items():\n",
    "        word = lemmas_to_words[lemma]\n",
    "        \n",
    "        pattern_word = [{'LOWER': str(word).lower(), 'op': '{1}'}]\n",
    "        pattern_word_w_punct = [{'LOWER': str(word).lower()},\n",
    "                                {'IS_PUNCT': True, 'op': '{1}'}]\n",
    "        pattern_word_w_space = [{'LOWER': str(word).lower()},\n",
    "                                {'SPACY': True, 'op': '{1}'}]\n",
    "        matcher.add(0, [pattern_word_w_space])\n",
    "        matcher.add(1, [pattern_word_w_punct])\n",
    "        matcher.add(2, [pattern_word])\n",
    "        \n",
    "        matches = matcher(new_doc)\n",
    "        match_id, start, end = matches[0]\n",
    "        \n",
    "        mat = np.matrix(matches, dtype=int)\n",
    "        keep_condit = (mat[:,1] == mat[:,1].min())\n",
    "        keep_indices = np.where(np.any(keep_condit, axis=1))\n",
    "        mat_first_word = mat[keep_indices, ]\n",
    "        patterns_matched_first_word = np.unique(mat_first_word[0][:, 0])\n",
    "        \n",
    "        if 1 in patterns_matched_first_word:  # precedes punct\n",
    "            repl_str = f\" {new_link}\"\n",
    "        elif 0 in patterns_matched_first_word:  # precedes space\n",
    "            repl_str = ''.join([f\" {new_link}\", \" \"])\n",
    "        else:\n",
    "            repl_str = f\" {new_link}\"\n",
    "        \n",
    "        new_doc = nlp.make_doc(new_doc[:start].text + repl_str + new_doc[end:].text)\n",
    "        \n",
    "        new_source_text[note_name] = new_doc\n",
    "        matcher.remove(0)\n",
    "        matcher.remove(1)\n",
    "        matcher.remove(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfda5f5",
   "metadata": {},
   "source": [
    "## write changes to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3448ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3afafe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_vault_dir = Path(os.getenv('FILM_NOIR_VAULT_DIR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6650596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vault_dir = Path.cwd() / \"vaults/film-noir-vault-new/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af11f090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/mark/Github/obsidian-nlp-analytics/vaults/film-noir-vault-new')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copytree(old_vault_dir, new_vault_dir, dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e8150f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for note_name, txt in new_source_text.items():\n",
    "    fpath = new_vault_dir / df.loc[note_name, 'rel_filepath']\n",
    "    with open(fpath, 'w') as f:\n",
    "        f.write(str(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b27fc7",
   "metadata": {},
   "source": [
    "Lemmas work quite well, but when specifying anchor words it is best to specify nouns, verbs & adjectives that carry the same meaning (e.g. 'desire' and 'desires').  Perhaps the user can make a MOC from words like that, to aid the navigation of a vault."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60187ce8",
   "metadata": {},
   "source": [
    "# Explore new vault that has auto-suggested links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee9a65f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obsidiantools.api import Vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3be1377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.16 s, sys: 14.8 ms, total: 5.17 s\n",
      "Wall time: 5.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NEW_VAULT = Vault(new_vault_dir).connect().gather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e07fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_vault = NEW_VAULT.get_note_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ea84e3",
   "metadata": {},
   "source": [
    "## Main new notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a90533",
   "metadata": {},
   "source": [
    "These are the main new (non-existent) notes in the Obsidian.md graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7b17433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "note\n",
       "kill            95\n",
       "murder          73\n",
       "dead            71\n",
       "gun             67\n",
       "die             62\n",
       "death           51\n",
       "crime           48\n",
       "love            44\n",
       "lie             40\n",
       "criminal        32\n",
       "control         30\n",
       "relationship    27\n",
       "sex             21\n",
       "lover           20\n",
       "fear            18\n",
       "Name: n_backlinks, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_new_vault.loc[~df_new_vault['note_exists'], 'n_backlinks']\n",
    " .sort_values(ascending=False)).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba1b58",
   "metadata": {},
   "source": [
    "Most films have been auto-suggested links such as `kill`, `murder` and `dead`.\n",
    "\n",
    "That's not surprising, as those aspects are a large part of film noir. ☠️\n",
    "\n",
    "Although less common, there are keywords involving romance (e.g. `love`, `relationship`).  Again, this is a major theme in film noir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1630d4ec",
   "metadata": {},
   "source": [
    "## Examples of new wikilinks added to notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fbb503",
   "metadata": {},
   "source": [
    "Example of a film with a few themes, which were successfully found to create wikilinks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c605085c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love',\n",
       " 'obsess',\n",
       " 'relationship',\n",
       " 'die',\n",
       " 'death',\n",
       " 'sex',\n",
       " 'murder',\n",
       " 'lie',\n",
       " 'kill']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_VAULT.wikilinks_index.get('Rebecca (1940)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab00a2b8",
   "metadata": {},
   "source": [
    "Sample of [_Laura_ (1944)](https://www.imdb.com/title/tt0037008/plotsummary#synopsis) synopsis, with wikilinks added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "840ebc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York City police detective Mark McPherson (Dana Andrews) is investigating the [[murder]] of beautiful, and highly successful, advertising executive, Laura Hunt (Gene Tierney). Laura has been [[kill|killed]] by a shotgun blast to the face, just inside the doorway to her apartment, before the start of the film. He interviews charismatic newspaper columnist Waldo Lydecker (Clifton Webb), an imperious, decadent dandy, who relates how he met Laura, became her mentor, and used his considerable influence and fame to advance her career.\n"
     ]
    }
   ],
   "source": [
    "# ~700 chars to show the first 2 auto-suggested wikilinks:\n",
    "print(NEW_VAULT.get_source_text('Laura (1944)')[:538])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e09126e",
   "metadata": {},
   "source": [
    "![Laura note](../img/film-noir_laura-1944_auto-suggested-wikilinks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ec1fc3",
   "metadata": {},
   "source": [
    "`Laura (1944)` has been auto-suggested the `jealous` note as a wikilink.  These are other film noir and neo-noir movies that have also had that auto-suggestion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300ff98a",
   "metadata": {},
   "source": [
    "![Jealous note](../img/film-noir_jealous-note_connections.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea8be0e",
   "metadata": {},
   "source": [
    "Film with most wikilinks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d2fb43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lost Highway (1997)\n",
      "Wikilinks: ['dead', 'love', 'lie', 'jealous', 'kill', 'death', 'murder', 'crime', 'violence', 'criminal', 'sex', 'gun', 'relationship', 'desire']\n"
     ]
    }
   ],
   "source": [
    "film_most_wikilinks = df_new_vault['n_wikilinks'].idxmax()\n",
    "print(film_most_wikilinks)\n",
    "print(\"Wikilinks:\", NEW_VAULT.wikilinks_index.get(film_most_wikilinks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16297b4",
   "metadata": {},
   "source": [
    "There are also a few films (e.g. Dark Passage) that have very short synoposes.  Their synopses on IMDB are short and so it is difficult to find keywords that align with the topics outlined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "623120f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Aura (2005)',\n",
       " 'Headhunters (2011)',\n",
       " 'Hangmen Also Die! (1943)',\n",
       " 'Dark Passage (1947)',\n",
       " 'Ace in the Hole (1951)']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_VAULT.isolated_notes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
